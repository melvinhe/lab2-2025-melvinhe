{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Part 3: Optimize Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goal: Minimize the energy and the area of caches\n",
    "\n",
    "In this part, we will design both the loop nest for matrix multiplication and the caches, to minimize the energy and the area of caches while correctly computing matrix multiplication. \n",
    "\n",
    "#### Matrix Multiplication Problem\n",
    "\n",
    "$$\n",
    "C_{m,n} = \\sum_k A_{m,k} \\times B_{k,n}\n",
    "$$\n",
    "\n",
    "where A is a $M\\times K$ matrix and B is a $K\\times N$ matrix. The matrix dimensions for our problem are $M=64, K=256, N=64$. You can write your own loop nest with any loop orders and tiling strategies that produce a correct result. \n",
    "\n",
    "#### Constraints on Cache Designs\n",
    "\n",
    "You can use any number of different caches (each with a __minimum size of 64 words__). You can have a hierarchy of caches, or multiple small caches, or a single large cache as you like. However the hard constraint on cache design is on the total area and energy of all caches you use:\n",
    "\n",
    "- Total Area: $20000 \\mu m^2$  \n",
    "- Total Energy: $1 m\\text{J}$\n",
    "\n",
    "You are not allowed to use a register for storing partial sums for this question. Thus, for each accumulate operation (```z[m][n] += a[m][k] * b[k][n]```), you must have one read and one write. The purpose of this question is to explore changing the addressing, cache sizes and tiling strategy. There are multiple possible solutions to achieve a full score. \n",
    "\n",
    "Please do not modify the setup code (such as ```z = z_MN.getRoot()```) nor perform your own matrix multiplication using numpy arrays. You are allowed to do this for debugging purposes, but for the final answer please utilize the setup we provide.\n",
    "\n",
    "#### Important Notes about Energy and Area\n",
    "Note the following facts about area.\n",
    "- Larger caches use more area.\n",
    "- Set-associative caches use more area than direct-mapped caches for the same total capacity due to overheads.\n",
    "\n",
    "Note the following facts about energy.\n",
    "- Here, we measure the total energy: the sum of cache and off-chip memory energies.\n",
    "- Off-chip memory reads and writes cost more energy than cache reads and writes.\n",
    "- A single read/write of a larger cache costs more energy than a read/write of a smaller cache.\n",
    "- A single read/write of a set-associative cache costs more energy than direct-mapped cache.\n",
    "\n",
    "#### Grading\n",
    "\n",
    "First, clearly explain your assumptions and loop nest details in the cell below. Also, make sure you explain assumptions for your memory layout (e.g., row-major or column-major) and cache designs. You can write a pseudo-code to explain your loop ordering and tiling strategies. Please also explain at which part of the loop nest you are expecting memory access (load and store). \n",
    "\n",
    "Second, make sure you correctly write `getAddress` function that will be used to compute memory address. This function should reflect your cache design.\n",
    "\n",
    "Third, report your total cache area and energy. Grading will be based on these metrics with maximum score of 10 for the total area, and 10 for the total energy:\n",
    "\n",
    "| Score | Area ($\\mu m^2$) | Energy ($m\\text{J}$) |\n",
    "| ---   | ----             | ----                 |\n",
    "| + 10  | < 12000          |  < 0.65              |\n",
    "| + 8   | 12000 ~ 14000    |  0.65 ~ 0.75         |\n",
    "| + 6   | 14000 ~ 16000    |  0.75 ~ 0.85         |\n",
    "| + 4   | 16000 ~ 18000    |  0.85 ~ 0.95         |\n",
    "| + 2   | 18000 ~ 20000    |  0.95 ~ 1.0          |\n",
    "\n",
    "Lastly, breakdown the total energy for each cache you used, and analyze which operation consumes the most energy. Is there any method to improve that operation? You do not need to implement any codes, but please conceptually explain what modifications can be made to caches to reduce energy further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d7df062c7f45bfbbf7b87d10a609a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='style', options=('tree', 'uncompressed', 'tree+uncompressed'), val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b7d7c33e5474236abe7c347c6e141f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Run all cells below', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run boilerplate code to set up environment\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "from loaders import *\n",
    "\n",
    "from cache import Cache, CacheAssoc\n",
    "\n",
    "%run ./prelude.py --style=uncompressed --animation=none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "density = [1.0]\n",
    "seed = 10\n",
    "\n",
    "enable_log = False\n",
    "\n",
    "def set_params(**kwargs):\n",
    "    global enable_log\n",
    "    \n",
    "    for variable, value in kwargs.items():\n",
    "        globals()[variable] = value\n",
    "\n",
    "    enable_log = (kwargs[\"log\"] == 'enable')\n",
    "\n",
    "\n",
    "def logger(arg):\n",
    "    if enable_log:\n",
    "        print(arg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Input Tensors\n",
    "\n",
    "Given shapes selected above the below codeblock creates and displays the filter weights (**f**) and input activations (**i**) and a reference output (**o_verify**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 64\n",
    "K = 256\n",
    "N = 64\n",
    "\n",
    "a_MK_raw = []\n",
    "for m in range(M):\n",
    "    a_MK_raw.append([random.randint(1, 9) for i in range(K)])\n",
    "                 \n",
    "b_KN_raw = []\n",
    "for k in range(K):\n",
    "    b_KN_raw.append([random.randint(1, 9) for i in range(N)])\n",
    "\n",
    "a_MK = Tensor.fromUncompressed([\"M\", \"K\"], a_MK_raw)\n",
    "b_KN = Tensor.fromUncompressed([\"K\", \"N\"], b_KN_raw)\n",
    "\n",
    "a_MK.setName(\"A_MK\").setColor(\"blue\")\n",
    "b_KN.setName(\"B_KN\").setColor(\"green\")\n",
    "\n",
    "# print(\"Input A\")\n",
    "# displayTensor(a_MK)\n",
    "                    \n",
    "# print(\"Input B\")\n",
    "# displayTensor(b_KN)\n",
    "\n",
    "z_verify = None\n",
    "\n",
    "def create_z():\n",
    "    \"\"\"\n",
    "    Create a fully populated z tensor\n",
    "    \"\"\"\n",
    "    z = Tensor(rank_ids=[\"M\", \"N\"], default='')\n",
    "    z.setName(\"Z\")\n",
    "    z.setMutable(True)\n",
    "\n",
    "    z_m = z.getRoot()\n",
    "    #\n",
    "    # Hack to fill in all the entries in z\n",
    "    # This allows us to pretend the tensor is dense\n",
    "    #\n",
    "    n_fiber = Fiber(coords=range(N), initial=1)\n",
    "    m_fiber = Fiber(coords=range(M), initial=1)\n",
    "\n",
    "    for m, (z_n, _) in z_m << m_fiber:\n",
    "        for n, (z_ref, _) in z_n << n_fiber:\n",
    "            z_ref <<= 0\n",
    "            \n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get ground truth for the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Multiply\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 64/64 [00:11<00:00,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Matrix Multiply\")\n",
    "\n",
    "z_MN = create_z()\n",
    "\n",
    "# print(\"Output - before\")\n",
    "# displayTensor(z_MN)\n",
    "\n",
    "z = z_MN.getRoot()\n",
    "a = a_MK.getRoot()\n",
    "b = b_KN.getRoot()\n",
    "\n",
    "# Progress bar since this takes a while\n",
    "pbar = tqdm.tqdm(desc='Progress', total=M)\n",
    "\n",
    "# canvas = createCanvas(a_MK, b_KN, z_MN)\n",
    "for m in range(M):\n",
    "    pbar.update(1)\n",
    "    a_tile = [ (m, kt) for kt in range(K)]\n",
    "    for n in range(N):\n",
    "        logger(f\"Processing Z({m},{n}) = {z[m][n]}\")\n",
    "        b_tile = [ (kt, n) for kt in range(K)]\n",
    "        z_tile = (m, n)\n",
    "        for k in range(K):\n",
    "            logger(f\"Processing A({m},{k}) = {a[m][k].payload}\")\n",
    "            logger(f\"Processing B({k},{n}) = {b[k][n].payload}\")\n",
    "            \n",
    "            z[m][n] += a[m][k] * b[k][n]\n",
    "            # addActivity(canvas, a_tile, b_tile, z_tile, worker=\"W\")\n",
    "            # addFrame(canvas, (m,k), (k,n), (m,n))\n",
    "print('Done!')  \n",
    "pbar.close()\n",
    "\n",
    "# print(\"Output - after\")\n",
    "# displayTensor(z)\n",
    "\n",
    "# displayCanvas(canvas)\n",
    "\n",
    "if z_verify is None:\n",
    "    z_verify = deepcopy(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9 \n",
    "\n",
    "Modify caches and loop nest below for your design. Run the cache profiler, and report the total area and energy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Code: Utility function for addressing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this function if necessary (e.g., different memory addressing)\n",
    "\n",
    "def getAddress(tensor, x, y):\n",
    "    return (x*tensor.getShape()[1]+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Code: Caches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use direct-mapped caches or set-associative caches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your caches; minimum size is log_size=6\n",
    "# You can use any number of separate caches, as far as they meet area and energy constraints\n",
    "\n",
    "cache_a = Cache(log_size=7, words_per_line=4)\n",
    "cache_b = Cache(log_size=7, words_per_line=4)\n",
    "cache_c = Cache(log_size=7, words_per_line=4)\n",
    "\n",
    "# List all caches you are using\n",
    "caches = [cache_a, cache_b, cache_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Code: Tiling and Loop Nest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Multiply\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 512/512 [01:16<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "-------Cache A--------\n",
      "Cache Statistics:\n",
      "cache rd: 1040384\n",
      "cache wr: 0\n",
      "mem rd: 8192\n",
      "mem wr: 0\n",
      "-------Cache B--------\n",
      "Cache Statistics:\n",
      "cache rd: 786432\n",
      "cache wr: 0\n",
      "mem rd: 262144\n",
      "mem wr: 0\n",
      "-------Cache C--------\n",
      "Cache Statistics:\n",
      "cache rd: 1015808\n",
      "cache wr: 32768\n",
      "mem rd: 32768\n",
      "mem wr: 131072\n"
     ]
    }
   ],
   "source": [
    "# Tiling Size: Modify this to change tiling\n",
    "\n",
    "# M = M1 x M0\n",
    "# K = K1 x K0\n",
    "# N = N1 x N0\n",
    "\n",
    "M1 = 8\n",
    "M0 = 8\n",
    "K1 = 32\n",
    "K0 = 8\n",
    "N1 = 2\n",
    "N0 = 32\n",
    "\n",
    "\n",
    "\n",
    "print(\"Matrix Multiply\")\n",
    "\n",
    "z_MN = create_z()\n",
    "\n",
    "# print(\"Output - before\")\n",
    "# displayTensor(z_MN)\n",
    "\n",
    "z = z_MN.getRoot()\n",
    "a = a_MK.getRoot()\n",
    "b = b_KN.getRoot()\n",
    "\n",
    "# canvas = createCanvas(a_MK, b_KN, z_MN)\n",
    "\n",
    "# Progress bar since this takes a while\n",
    "pbar = tqdm.tqdm(desc='Progress', total=K1*M1*N1)\n",
    "\n",
    "# Loop Nest: Modify this to alter the for loop orders\n",
    "for m1 in range(M1):\n",
    "    for n1 in range(N1):\n",
    "        for k1 in range(K1):\n",
    "            pbar.update(1)\n",
    "            \n",
    "            write_buffer = {}\n",
    "\n",
    "            for m0 in range(M0):\n",
    "                for k0 in range(K0):\n",
    "                    for n0 in range(N0):\n",
    "\n",
    "                        m, k, n = m1 * M0 + m0, k1 * K0 + k0, n1 * N0 + n0\n",
    "\n",
    "                        cache_a.load(getAddress(a, m, k))\n",
    "                        cache_b.load(getAddress(b, k, n))\n",
    "                        cache_c.load(getAddress(z, m, n))\n",
    "\n",
    "                        z[m][n] += a[m][k] * b[k][n]\n",
    "\n",
    "                        write_buffer[(m, n)] = z[m][n]\n",
    "\n",
    "            for (m, n), value in write_buffer.items():\n",
    "                cache_c.store(getAddress(z, m, n))\n",
    "\n",
    "print('Done!')\n",
    "pbar.close()\n",
    "# print(\"Output - after\")\n",
    "# displayTensor(z)\n",
    "\n",
    "# displayCanvas(canvas)\n",
    "\n",
    "if z_verify is None:\n",
    "    print(\"Result not verified\")\n",
    "else:\n",
    "    assert z == z_verify\n",
    "\n",
    "# Print cache statistics\n",
    "print(\"-------Cache A--------\")\n",
    "cache_a.print_stats()\n",
    "print(\"-------Cache B--------\")\n",
    "cache_b.print_stats()\n",
    "print(\"-------Cache C--------\")\n",
    "cache_c.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Area / Energy Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache 1 Energy: 0.0063 mj, Area: 2659.82 um^2\n",
      "Cache 2 Energy: 0.1363 mj, Area: 2659.82 um^2\n",
      "Cache 3 Energy: 0.0860 mj, Area: 2659.82 um^2\n",
      "Total Energy: 0.2286 mj, Area: 7979.46 um^2\n",
      "3.1.1: \n",
      "\tTrue\n",
      "3.1.1: \n",
      "\tTrue\n",
      "3.1.1: \n",
      "\tTrue\n",
      "3.1.1: \n",
      "\tTrue\n",
      "3.1.1: \n",
      "\tTrue\n",
      "3.1.2: \n",
      "\tTrue\n",
      "3.1.2: \n",
      "\tTrue\n",
      "3.1.2: \n",
      "\tTrue\n",
      "3.1.2: \n",
      "\tTrue\n",
      "3.1.2: \n",
      "\tTrue\n"
     ]
    }
   ],
   "source": [
    "# You do not need to change any of this part.\n",
    "from cache_profiler import CacheProfiler\n",
    "\n",
    "res_list = []\n",
    "for cache in caches:\n",
    "    profiler = CacheProfiler(cache)\n",
    "    res = profiler.profile(cache.stats)\n",
    "    res_list.append(res)\n",
    "\n",
    "total_energy = 0\n",
    "total_area = 0\n",
    "for i, res in enumerate(res_list):\n",
    "    print(f\"Cache {i+1} Energy: {res['energy'] / 1e9 :.4f} mj, Area: {res['area'] :.2f} um^2\")\n",
    "    total_energy += res['energy']\n",
    "    total_area += res['area']\n",
    "\n",
    "total_energy /= 1e9 # Convert to mJ\n",
    "print(f\"Total Energy: {total_energy :.4f} mj, Area: {total_area :.2f} um^2\")\n",
    "\n",
    "answer( # DO NOT MODIFY\n",
    "    question='3.1.1',\n",
    "    subquestion='',\n",
    "    answer=total_energy<1.0,\n",
    "    required_type=bool,\n",
    ")\n",
    "answer( # DO NOT MODIFY\n",
    "    question='3.1.1',\n",
    "    subquestion='',\n",
    "    answer=total_energy<0.95,\n",
    "    required_type=bool,\n",
    ")\n",
    "answer( # DO NOT MODIFY\n",
    "    question='3.1.1',\n",
    "    subquestion='',\n",
    "    answer=total_energy<0.85,\n",
    "    required_type=bool,\n",
    ")\n",
    "answer( # DO NOT MODIFY\n",
    "    question='3.1.1',\n",
    "    subquestion='',\n",
    "    answer=total_energy<0.75,\n",
    "    required_type=bool,\n",
    ")\n",
    "answer( # DO NOT MODIFY\n",
    "    question='3.1.1',\n",
    "    subquestion='',\n",
    "    answer=total_energy<0.65,\n",
    "    required_type=bool,\n",
    ")\n",
    "answer( # DO NOT MODIFY\n",
    "    question='3.1.2',\n",
    "    subquestion='',\n",
    "    answer=total_area<20000,\n",
    "    required_type=bool,\n",
    ")\n",
    "answer( # DO NOT MODIFY\n",
    "    question='3.1.2',\n",
    "    subquestion='',\n",
    "    answer=total_area<18000,\n",
    "    required_type=bool,\n",
    ")\n",
    "answer( # DO NOT MODIFY\n",
    "    question='3.1.2',\n",
    "    subquestion='',\n",
    "    answer=total_area<16000,\n",
    "    required_type=bool,\n",
    ")\n",
    "answer( # DO NOT MODIFY\n",
    "    question='3.1.2',\n",
    "    subquestion='',\n",
    "    answer=total_area<14000,\n",
    "    required_type=bool,\n",
    ")\n",
    "answer( # DO NOT MODIFY\n",
    "    question='3.1.2',\n",
    "    subquestion='',\n",
    "    answer=total_area<12000,\n",
    "    required_type=bool,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
